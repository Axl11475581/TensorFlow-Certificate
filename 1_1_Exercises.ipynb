{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "1.1 - Exercises.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "authorship_tag": "ABX9TyNPfhW8Ks+rvBEcIuE0KVbK",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Axl11475581/TensorFlow-Certificate/blob/main/1_1_Exercises.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vHKDTDs4eAyR"
      },
      "source": [
        "## In this notebook the exercises from the **1.0 - N.N/Regression** will be cover."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "twVdIb_OePdM"
      },
      "source": [
        "1. Create your own regression dataset (or make the one we created in \"Create data to view and fit\" bigger) and build, fit a model to it"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jMlJadSdelbm",
        "outputId": "6ed8350a-9cba-40e6-e646-00ccd7fa9c03"
      },
      "source": [
        "# Import libraries\n",
        "import tensorflow as tf\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "print(tf.__version__)"
      ],
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "2.5.0\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 265
        },
        "id": "Akek8j_Oe1nM",
        "outputId": "90a3d7c6-6413-4302-adbe-8c433a5253e1"
      },
      "source": [
        "# Features \n",
        "X = np.array([-7.0, -4.0, -1.0, 2.0, 5.0, 8.0, 11.0, 14.0, 17.0, 20.0, 23.0, 26.0, 29.0, 32.0, 35.0, 38.0, 42.0, 45.0, 48.0, 51.0, 54.0, 57.0, 60.0])\n",
        "\n",
        "# Labels\n",
        "y = np.array([3.0, 6.0, 9.0, 12.0, 15.0, 18.0, 21.0, 24.0, 27.0, 30.0, 33.0, 36.0, 39.0, 42.0, 45.0, 48.0, 52.0, 55.0, 58.0, 61.0, 64.0, 67.0, 70.0])\n",
        "\n",
        "# Visualization\n",
        "plt.scatter(X, y);"
      ],
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6qk6n3RQhHvU",
        "outputId": "f1ea7464-c0cb-4206-c4e5-72f65983e8dc"
      },
      "source": [
        "# Truning the NumPy arrays into tensors\n",
        "X = tf.cast(tf.constant(X), dtype=tf.float32)\n",
        "y = tf.cast(tf.constant(y), dtype=tf.float32)\n",
        "X, y"
      ],
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(<tf.Tensor: shape=(23,), dtype=float32, numpy=\n",
              " array([-7., -4., -1.,  2.,  5.,  8., 11., 14., 17., 20., 23., 26., 29.,\n",
              "        32., 35., 38., 42., 45., 48., 51., 54., 57., 60.], dtype=float32)>,\n",
              " <tf.Tensor: shape=(23,), dtype=float32, numpy=\n",
              " array([ 3.,  6.,  9., 12., 15., 18., 21., 24., 27., 30., 33., 36., 39.,\n",
              "        42., 45., 48., 52., 55., 58., 61., 64., 67., 70.], dtype=float32)>)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 16
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LMsOFSg3jOGF"
      },
      "source": [
        "2. Try building a neural network with 4 Dense layers and fitting it to your own regression dataset, how does it perform?"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "b8Tk2_XThZ3a",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "a0b81a24-e040-4915-cbe4-9a6394014741"
      },
      "source": [
        "# Making the model\n",
        "model = tf.keras.Sequential([\n",
        "  tf.keras.layers.Dense(100),\n",
        "  tf.keras.layers.Dense(50),\n",
        "  tf.keras.layers.Dense(10),\n",
        "  tf.keras.layers.Dense(1)\n",
        "])\n",
        "\n",
        "# Compile\n",
        "model.compile(loss=tf.keras.losses.mae, \n",
        "              optimizer=tf.keras.optimizers.Adam(), \n",
        "              metrics=[\"mae\"])\n",
        "\n",
        "# Fit\n",
        "model.fit(X, y, epochs=200)"
      ],
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/200\n",
            "1/1 [==============================] - 0s 413ms/step - loss: 42.0482 - mae: 42.0482\n",
            "Epoch 2/200\n",
            "1/1 [==============================] - 0s 8ms/step - loss: 38.5191 - mae: 38.5191\n",
            "Epoch 3/200\n",
            "1/1 [==============================] - 0s 8ms/step - loss: 34.9893 - mae: 34.9893\n",
            "Epoch 4/200\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 31.4510 - mae: 31.4510\n",
            "Epoch 5/200\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 27.8932 - mae: 27.8932\n",
            "Epoch 6/200\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 24.3031 - mae: 24.3031\n",
            "Epoch 7/200\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 20.6696 - mae: 20.6696\n",
            "Epoch 8/200\n",
            "1/1 [==============================] - 0s 4ms/step - loss: 16.9823 - mae: 16.9823\n",
            "Epoch 9/200\n",
            "1/1 [==============================] - 0s 8ms/step - loss: 13.2301 - mae: 13.2301\n",
            "Epoch 10/200\n",
            "1/1 [==============================] - 0s 10ms/step - loss: 9.4017 - mae: 9.4017\n",
            "Epoch 11/200\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 5.4852 - mae: 5.4852\n",
            "Epoch 12/200\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 5.6010 - mae: 5.6010\n",
            "Epoch 13/200\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 7.7251 - mae: 7.7251\n",
            "Epoch 14/200\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 9.5856 - mae: 9.5856\n",
            "Epoch 15/200\n",
            "1/1 [==============================] - 0s 8ms/step - loss: 10.7959 - mae: 10.7959\n",
            "Epoch 16/200\n",
            "1/1 [==============================] - 0s 4ms/step - loss: 11.3620 - mae: 11.3620\n",
            "Epoch 17/200\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 11.3387 - mae: 11.3387\n",
            "Epoch 18/200\n",
            "1/1 [==============================] - 0s 8ms/step - loss: 10.8313 - mae: 10.8313\n",
            "Epoch 19/200\n",
            "1/1 [==============================] - 0s 4ms/step - loss: 9.9673 - mae: 9.9673\n",
            "Epoch 20/200\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 8.8442 - mae: 8.8442\n",
            "Epoch 21/200\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 7.5876 - mae: 7.5876\n",
            "Epoch 22/200\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 6.3334 - mae: 6.3334\n",
            "Epoch 23/200\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 5.3105 - mae: 5.3105\n",
            "Epoch 24/200\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 4.8271 - mae: 4.8271\n",
            "Epoch 25/200\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 5.3924 - mae: 5.3924\n",
            "Epoch 26/200\n",
            "1/1 [==============================] - 0s 10ms/step - loss: 6.3871 - mae: 6.3871\n",
            "Epoch 27/200\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 6.8425 - mae: 6.8425\n",
            "Epoch 28/200\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 6.8373 - mae: 6.8373\n",
            "Epoch 29/200\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 6.4312 - mae: 6.4312\n",
            "Epoch 30/200\n",
            "1/1 [==============================] - 0s 17ms/step - loss: 5.6699 - mae: 5.6699\n",
            "Epoch 31/200\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 4.8902 - mae: 4.8902\n",
            "Epoch 32/200\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 4.7899 - mae: 4.7899\n",
            "Epoch 33/200\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 4.9902 - mae: 4.9902\n",
            "Epoch 34/200\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 5.2577 - mae: 5.2577\n",
            "Epoch 35/200\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 5.4798 - mae: 5.4798\n",
            "Epoch 36/200\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 5.5745 - mae: 5.5745\n",
            "Epoch 37/200\n",
            "1/1 [==============================] - 0s 9ms/step - loss: 5.5384 - mae: 5.5384\n",
            "Epoch 38/200\n",
            "1/1 [==============================] - 0s 16ms/step - loss: 5.3843 - mae: 5.3843\n",
            "Epoch 39/200\n",
            "1/1 [==============================] - 0s 9ms/step - loss: 5.1554 - mae: 5.1554\n",
            "Epoch 40/200\n",
            "1/1 [==============================] - 0s 8ms/step - loss: 4.9189 - mae: 4.9189\n",
            "Epoch 41/200\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 4.7512 - mae: 4.7512\n",
            "Epoch 42/200\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 4.6940 - mae: 4.6940\n",
            "Epoch 43/200\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 4.7990 - mae: 4.7990\n",
            "Epoch 44/200\n",
            "1/1 [==============================] - 0s 8ms/step - loss: 4.9494 - mae: 4.9494\n",
            "Epoch 45/200\n",
            "1/1 [==============================] - 0s 8ms/step - loss: 4.9633 - mae: 4.9633\n",
            "Epoch 46/200\n",
            "1/1 [==============================] - 0s 8ms/step - loss: 4.8333 - mae: 4.8333\n",
            "Epoch 47/200\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 4.6915 - mae: 4.6915\n",
            "Epoch 48/200\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 4.6368 - mae: 4.6368\n",
            "Epoch 49/200\n",
            "1/1 [==============================] - 0s 13ms/step - loss: 4.6632 - mae: 4.6632\n",
            "Epoch 50/200\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 4.7079 - mae: 4.7079\n",
            "Epoch 51/200\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 4.7397 - mae: 4.7397\n",
            "Epoch 52/200\n",
            "1/1 [==============================] - 0s 8ms/step - loss: 4.7427 - mae: 4.7427\n",
            "Epoch 53/200\n",
            "1/1 [==============================] - 0s 9ms/step - loss: 4.7032 - mae: 4.7032\n",
            "Epoch 54/200\n",
            "1/1 [==============================] - 0s 10ms/step - loss: 4.6626 - mae: 4.6626\n",
            "Epoch 55/200\n",
            "1/1 [==============================] - 0s 8ms/step - loss: 4.6105 - mae: 4.6105\n",
            "Epoch 56/200\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 4.5655 - mae: 4.5655\n",
            "Epoch 57/200\n",
            "1/1 [==============================] - 0s 10ms/step - loss: 4.5509 - mae: 4.5509\n",
            "Epoch 58/200\n",
            "1/1 [==============================] - 0s 8ms/step - loss: 4.5645 - mae: 4.5645\n",
            "Epoch 59/200\n",
            "1/1 [==============================] - 0s 10ms/step - loss: 4.5782 - mae: 4.5782\n",
            "Epoch 60/200\n",
            "1/1 [==============================] - 0s 9ms/step - loss: 4.5657 - mae: 4.5657\n",
            "Epoch 61/200\n",
            "1/1 [==============================] - 0s 9ms/step - loss: 4.5323 - mae: 4.5323\n",
            "Epoch 62/200\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 4.5012 - mae: 4.5012\n",
            "Epoch 63/200\n",
            "1/1 [==============================] - 0s 9ms/step - loss: 4.4909 - mae: 4.4909\n",
            "Epoch 64/200\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 4.4869 - mae: 4.4869\n",
            "Epoch 65/200\n",
            "1/1 [==============================] - 0s 9ms/step - loss: 4.5004 - mae: 4.5004\n",
            "Epoch 66/200\n",
            "1/1 [==============================] - 0s 9ms/step - loss: 4.4980 - mae: 4.4980\n",
            "Epoch 67/200\n",
            "1/1 [==============================] - 0s 8ms/step - loss: 4.4791 - mae: 4.4791\n",
            "Epoch 68/200\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 4.4452 - mae: 4.4452\n",
            "Epoch 69/200\n",
            "1/1 [==============================] - 0s 17ms/step - loss: 4.4264 - mae: 4.4264\n",
            "Epoch 70/200\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 4.4154 - mae: 4.4154\n",
            "Epoch 71/200\n",
            "1/1 [==============================] - 0s 8ms/step - loss: 4.4192 - mae: 4.4192\n",
            "Epoch 72/200\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 4.4147 - mae: 4.4147\n",
            "Epoch 73/200\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 4.4025 - mae: 4.4025\n",
            "Epoch 74/200\n",
            "1/1 [==============================] - 0s 9ms/step - loss: 4.3833 - mae: 4.3833\n",
            "Epoch 75/200\n",
            "1/1 [==============================] - 0s 33ms/step - loss: 4.3577 - mae: 4.3577\n",
            "Epoch 76/200\n",
            "1/1 [==============================] - 0s 11ms/step - loss: 4.3481 - mae: 4.3481\n",
            "Epoch 77/200\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 4.3415 - mae: 4.3415\n",
            "Epoch 78/200\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 4.3395 - mae: 4.3395\n",
            "Epoch 79/200\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 4.3285 - mae: 4.3285\n",
            "Epoch 80/200\n",
            "1/1 [==============================] - 0s 9ms/step - loss: 4.3075 - mae: 4.3075\n",
            "Epoch 81/200\n",
            "1/1 [==============================] - 0s 11ms/step - loss: 4.2923 - mae: 4.2923\n",
            "Epoch 82/200\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 4.2767 - mae: 4.2767\n",
            "Epoch 83/200\n",
            "1/1 [==============================] - 0s 8ms/step - loss: 4.2665 - mae: 4.2665\n",
            "Epoch 84/200\n",
            "1/1 [==============================] - 0s 14ms/step - loss: 4.2598 - mae: 4.2598\n",
            "Epoch 85/200\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 4.2449 - mae: 4.2449\n",
            "Epoch 86/200\n",
            "1/1 [==============================] - 0s 8ms/step - loss: 4.2275 - mae: 4.2275\n",
            "Epoch 87/200\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 4.2175 - mae: 4.2175\n",
            "Epoch 88/200\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 4.2066 - mae: 4.2066\n",
            "Epoch 89/200\n",
            "1/1 [==============================] - 0s 8ms/step - loss: 4.1948 - mae: 4.1948\n",
            "Epoch 90/200\n",
            "1/1 [==============================] - 0s 8ms/step - loss: 4.1823 - mae: 4.1823\n",
            "Epoch 91/200\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 4.1690 - mae: 4.1690\n",
            "Epoch 92/200\n",
            "1/1 [==============================] - 0s 8ms/step - loss: 4.1551 - mae: 4.1551\n",
            "Epoch 93/200\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 4.1406 - mae: 4.1406\n",
            "Epoch 94/200\n",
            "1/1 [==============================] - 0s 9ms/step - loss: 4.1344 - mae: 4.1344\n",
            "Epoch 95/200\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 4.1211 - mae: 4.1211\n",
            "Epoch 96/200\n",
            "1/1 [==============================] - 0s 8ms/step - loss: 4.1028 - mae: 4.1028\n",
            "Epoch 97/200\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 4.0915 - mae: 4.0915\n",
            "Epoch 98/200\n",
            "1/1 [==============================] - 0s 9ms/step - loss: 4.0793 - mae: 4.0793\n",
            "Epoch 99/200\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 4.0663 - mae: 4.0663\n",
            "Epoch 100/200\n",
            "1/1 [==============================] - 0s 16ms/step - loss: 4.0525 - mae: 4.0525\n",
            "Epoch 101/200\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 4.0380 - mae: 4.0380\n",
            "Epoch 102/200\n",
            "1/1 [==============================] - 0s 9ms/step - loss: 4.0243 - mae: 4.0243\n",
            "Epoch 103/200\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 4.0103 - mae: 4.0103\n",
            "Epoch 104/200\n",
            "1/1 [==============================] - 0s 9ms/step - loss: 3.9968 - mae: 3.9968\n",
            "Epoch 105/200\n",
            "1/1 [==============================] - 0s 8ms/step - loss: 3.9825 - mae: 3.9825\n",
            "Epoch 106/200\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 3.9725 - mae: 3.9725\n",
            "Epoch 107/200\n",
            "1/1 [==============================] - 0s 10ms/step - loss: 3.9551 - mae: 3.9551\n",
            "Epoch 108/200\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 3.9417 - mae: 3.9417\n",
            "Epoch 109/200\n",
            "1/1 [==============================] - 0s 4ms/step - loss: 3.9274 - mae: 3.9274\n",
            "Epoch 110/200\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 3.9124 - mae: 3.9124\n",
            "Epoch 111/200\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 3.9024 - mae: 3.9024\n",
            "Epoch 112/200\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 3.8835 - mae: 3.8835\n",
            "Epoch 113/200\n",
            "1/1 [==============================] - 0s 8ms/step - loss: 3.8693 - mae: 3.8693\n",
            "Epoch 114/200\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 3.8544 - mae: 3.8544\n",
            "Epoch 115/200\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 3.8404 - mae: 3.8404\n",
            "Epoch 116/200\n",
            "1/1 [==============================] - 0s 10ms/step - loss: 3.8253 - mae: 3.8253\n",
            "Epoch 117/200\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 3.8111 - mae: 3.8111\n",
            "Epoch 118/200\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 3.7959 - mae: 3.7959\n",
            "Epoch 119/200\n",
            "1/1 [==============================] - 0s 9ms/step - loss: 3.7799 - mae: 3.7799\n",
            "Epoch 120/200\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 3.7631 - mae: 3.7631\n",
            "Epoch 121/200\n",
            "1/1 [==============================] - 0s 10ms/step - loss: 3.7487 - mae: 3.7487\n",
            "Epoch 122/200\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 3.7308 - mae: 3.7308\n",
            "Epoch 123/200\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 3.7149 - mae: 3.7149\n",
            "Epoch 124/200\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 3.6982 - mae: 3.6982\n",
            "Epoch 125/200\n",
            "1/1 [==============================] - 0s 9ms/step - loss: 3.6829 - mae: 3.6829\n",
            "Epoch 126/200\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 3.6658 - mae: 3.6658\n",
            "Epoch 127/200\n",
            "1/1 [==============================] - 0s 8ms/step - loss: 3.6499 - mae: 3.6499\n",
            "Epoch 128/200\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 3.6329 - mae: 3.6329\n",
            "Epoch 129/200\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 3.6151 - mae: 3.6151\n",
            "Epoch 130/200\n",
            "1/1 [==============================] - 0s 24ms/step - loss: 3.5964 - mae: 3.5964\n",
            "Epoch 131/200\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 3.5813 - mae: 3.5813\n",
            "Epoch 132/200\n",
            "1/1 [==============================] - 0s 11ms/step - loss: 3.5603 - mae: 3.5603\n",
            "Epoch 133/200\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 3.5425 - mae: 3.5425\n",
            "Epoch 134/200\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 3.5238 - mae: 3.5238\n",
            "Epoch 135/200\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 3.5064 - mae: 3.5064\n",
            "Epoch 136/200\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 3.4874 - mae: 3.4874\n",
            "Epoch 137/200\n",
            "1/1 [==============================] - 0s 8ms/step - loss: 3.4693 - mae: 3.4693\n",
            "Epoch 138/200\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 3.4502 - mae: 3.4502\n",
            "Epoch 139/200\n",
            "1/1 [==============================] - 0s 9ms/step - loss: 3.4301 - mae: 3.4301\n",
            "Epoch 140/200\n",
            "1/1 [==============================] - 0s 8ms/step - loss: 3.4091 - mae: 3.4091\n",
            "Epoch 141/200\n",
            "1/1 [==============================] - 0s 9ms/step - loss: 3.3882 - mae: 3.3882\n",
            "Epoch 142/200\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 3.3682 - mae: 3.3682\n",
            "Epoch 143/200\n",
            "1/1 [==============================] - 0s 10ms/step - loss: 3.3480 - mae: 3.3480\n",
            "Epoch 144/200\n",
            "1/1 [==============================] - 0s 8ms/step - loss: 3.3267 - mae: 3.3267\n",
            "Epoch 145/200\n",
            "1/1 [==============================] - 0s 12ms/step - loss: 3.3044 - mae: 3.3044\n",
            "Epoch 146/200\n",
            "1/1 [==============================] - 0s 11ms/step - loss: 3.2846 - mae: 3.2846\n",
            "Epoch 147/200\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 3.2608 - mae: 3.2608\n",
            "Epoch 148/200\n",
            "1/1 [==============================] - 0s 8ms/step - loss: 3.2392 - mae: 3.2392\n",
            "Epoch 149/200\n",
            "1/1 [==============================] - 0s 11ms/step - loss: 3.2165 - mae: 3.2165\n",
            "Epoch 150/200\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 3.1926 - mae: 3.1926\n",
            "Epoch 151/200\n",
            "1/1 [==============================] - 0s 9ms/step - loss: 3.1688 - mae: 3.1688\n",
            "Epoch 152/200\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 3.1458 - mae: 3.1458\n",
            "Epoch 153/200\n",
            "1/1 [==============================] - 0s 10ms/step - loss: 3.1225 - mae: 3.1225\n",
            "Epoch 154/200\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 3.0980 - mae: 3.0980\n",
            "Epoch 155/200\n",
            "1/1 [==============================] - 0s 42ms/step - loss: 3.0723 - mae: 3.0723\n",
            "Epoch 156/200\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 3.0455 - mae: 3.0455\n",
            "Epoch 157/200\n",
            "1/1 [==============================] - 0s 8ms/step - loss: 3.0227 - mae: 3.0227\n",
            "Epoch 158/200\n",
            "1/1 [==============================] - 0s 11ms/step - loss: 2.9927 - mae: 2.9927\n",
            "Epoch 159/200\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 2.9665 - mae: 2.9665\n",
            "Epoch 160/200\n",
            "1/1 [==============================] - 0s 10ms/step - loss: 2.9390 - mae: 2.9390\n",
            "Epoch 161/200\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 2.9102 - mae: 2.9102\n",
            "Epoch 162/200\n",
            "1/1 [==============================] - 0s 13ms/step - loss: 2.8885 - mae: 2.8885\n",
            "Epoch 163/200\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 2.8533 - mae: 2.8533\n",
            "Epoch 164/200\n",
            "1/1 [==============================] - 0s 8ms/step - loss: 2.8249 - mae: 2.8249\n",
            "Epoch 165/200\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 2.7950 - mae: 2.7950\n",
            "Epoch 166/200\n",
            "1/1 [==============================] - 0s 18ms/step - loss: 2.7637 - mae: 2.7637\n",
            "Epoch 167/200\n",
            "1/1 [==============================] - 0s 11ms/step - loss: 2.7349 - mae: 2.7349\n",
            "Epoch 168/200\n",
            "1/1 [==============================] - 0s 8ms/step - loss: 2.7017 - mae: 2.7017\n",
            "Epoch 169/200\n",
            "1/1 [==============================] - 0s 12ms/step - loss: 2.6707 - mae: 2.6707\n",
            "Epoch 170/200\n",
            "1/1 [==============================] - 0s 10ms/step - loss: 2.6380 - mae: 2.6380\n",
            "Epoch 171/200\n",
            "1/1 [==============================] - 0s 13ms/step - loss: 2.6037 - mae: 2.6037\n",
            "Epoch 172/200\n",
            "1/1 [==============================] - 0s 14ms/step - loss: 2.5679 - mae: 2.5679\n",
            "Epoch 173/200\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 2.5371 - mae: 2.5371\n",
            "Epoch 174/200\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 2.4969 - mae: 2.4969\n",
            "Epoch 175/200\n",
            "1/1 [==============================] - 0s 20ms/step - loss: 2.4613 - mae: 2.4613\n",
            "Epoch 176/200\n",
            "1/1 [==============================] - 0s 8ms/step - loss: 2.4240 - mae: 2.4240\n",
            "Epoch 177/200\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 2.3849 - mae: 2.3849\n",
            "Epoch 178/200\n",
            "1/1 [==============================] - 0s 9ms/step - loss: 2.3530 - mae: 2.3530\n",
            "Epoch 179/200\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 2.3070 - mae: 2.3070\n",
            "Epoch 180/200\n",
            "1/1 [==============================] - 0s 9ms/step - loss: 2.2678 - mae: 2.2678\n",
            "Epoch 181/200\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 2.2266 - mae: 2.2266\n",
            "Epoch 182/200\n",
            "1/1 [==============================] - 0s 12ms/step - loss: 2.1833 - mae: 2.1833\n",
            "Epoch 183/200\n",
            "1/1 [==============================] - 0s 8ms/step - loss: 2.1415 - mae: 2.1415\n",
            "Epoch 184/200\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 2.0970 - mae: 2.0970\n",
            "Epoch 185/200\n",
            "1/1 [==============================] - 0s 10ms/step - loss: 2.0535 - mae: 2.0535\n",
            "Epoch 186/200\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 2.0076 - mae: 2.0076\n",
            "Epoch 187/200\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 1.9595 - mae: 1.9595\n",
            "Epoch 188/200\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 1.9092 - mae: 1.9092\n",
            "Epoch 189/200\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 1.8659 - mae: 1.8659\n",
            "Epoch 190/200\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 1.8087 - mae: 1.8087\n",
            "Epoch 191/200\n",
            "1/1 [==============================] - 0s 8ms/step - loss: 1.7580 - mae: 1.7580\n",
            "Epoch 192/200\n",
            "1/1 [==============================] - 0s 10ms/step - loss: 1.7046 - mae: 1.7046\n",
            "Epoch 193/200\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 1.6504 - mae: 1.6504\n",
            "Epoch 194/200\n",
            "1/1 [==============================] - 0s 8ms/step - loss: 1.5982 - mae: 1.5982\n",
            "Epoch 195/200\n",
            "1/1 [==============================] - 0s 11ms/step - loss: 1.5383 - mae: 1.5383\n",
            "Epoch 196/200\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 1.4806 - mae: 1.4806\n",
            "Epoch 197/200\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 1.4216 - mae: 1.4216\n",
            "Epoch 198/200\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 1.3596 - mae: 1.3596\n",
            "Epoch 199/200\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 1.3020 - mae: 1.3020\n",
            "Epoch 200/200\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 1.2348 - mae: 1.2348\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tensorflow.python.keras.callbacks.History at 0x7f1de0224710>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 17
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vQVRhdiVhvGL",
        "outputId": "a61c1843-139f-48e7-8984-46f573ce45ef"
      },
      "source": [
        "# Make a prediction\n",
        "y_pred = model.predict([15.0])\n",
        "y_pred"
      ],
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[23.55411]], dtype=float32)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 18
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FYt0wItDh4tQ"
      },
      "source": [
        "3. Try and improve the results we got on the insurance dataset, some things you might want to try include:\n",
        "\n",
        "* Building a larger model \n",
        "* Increasing the number of units in each layer.\n",
        "* Lookup the documentation of Adam and find out what the first parameter is, what happens if you increase it by 10x?\n",
        "* What happens if you train for longer? (say 300 epochs instead of 200)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "g_3643PPkc_9"
      },
      "source": [
        "# Import required libraries\n",
        "import tensorflow as tf\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt"
      ],
      "execution_count": 19,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 424
        },
        "id": "pLt5ljktk3nU",
        "outputId": "03f1167b-a295-4994-fde3-a7f5a68043a0"
      },
      "source": [
        "# Read in the insurance dataset\n",
        "insurance = pd.read_csv(\"https://raw.githubusercontent.com/stedy/Machine-Learning-with-R-datasets/master/insurance.csv\")\n",
        "insurance"
      ],
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>age</th>\n",
              "      <th>sex</th>\n",
              "      <th>bmi</th>\n",
              "      <th>children</th>\n",
              "      <th>smoker</th>\n",
              "      <th>region</th>\n",
              "      <th>charges</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>19</td>\n",
              "      <td>female</td>\n",
              "      <td>27.900</td>\n",
              "      <td>0</td>\n",
              "      <td>yes</td>\n",
              "      <td>southwest</td>\n",
              "      <td>16884.92400</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>18</td>\n",
              "      <td>male</td>\n",
              "      <td>33.770</td>\n",
              "      <td>1</td>\n",
              "      <td>no</td>\n",
              "      <td>southeast</td>\n",
              "      <td>1725.55230</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>28</td>\n",
              "      <td>male</td>\n",
              "      <td>33.000</td>\n",
              "      <td>3</td>\n",
              "      <td>no</td>\n",
              "      <td>southeast</td>\n",
              "      <td>4449.46200</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>33</td>\n",
              "      <td>male</td>\n",
              "      <td>22.705</td>\n",
              "      <td>0</td>\n",
              "      <td>no</td>\n",
              "      <td>northwest</td>\n",
              "      <td>21984.47061</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>32</td>\n",
              "      <td>male</td>\n",
              "      <td>28.880</td>\n",
              "      <td>0</td>\n",
              "      <td>no</td>\n",
              "      <td>northwest</td>\n",
              "      <td>3866.85520</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1333</th>\n",
              "      <td>50</td>\n",
              "      <td>male</td>\n",
              "      <td>30.970</td>\n",
              "      <td>3</td>\n",
              "      <td>no</td>\n",
              "      <td>northwest</td>\n",
              "      <td>10600.54830</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1334</th>\n",
              "      <td>18</td>\n",
              "      <td>female</td>\n",
              "      <td>31.920</td>\n",
              "      <td>0</td>\n",
              "      <td>no</td>\n",
              "      <td>northeast</td>\n",
              "      <td>2205.98080</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1335</th>\n",
              "      <td>18</td>\n",
              "      <td>female</td>\n",
              "      <td>36.850</td>\n",
              "      <td>0</td>\n",
              "      <td>no</td>\n",
              "      <td>southeast</td>\n",
              "      <td>1629.83350</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1336</th>\n",
              "      <td>21</td>\n",
              "      <td>female</td>\n",
              "      <td>25.800</td>\n",
              "      <td>0</td>\n",
              "      <td>no</td>\n",
              "      <td>southwest</td>\n",
              "      <td>2007.94500</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1337</th>\n",
              "      <td>61</td>\n",
              "      <td>female</td>\n",
              "      <td>29.070</td>\n",
              "      <td>0</td>\n",
              "      <td>yes</td>\n",
              "      <td>northwest</td>\n",
              "      <td>29141.36030</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>1338 rows × 7 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "      age     sex     bmi  children smoker     region      charges\n",
              "0      19  female  27.900         0    yes  southwest  16884.92400\n",
              "1      18    male  33.770         1     no  southeast   1725.55230\n",
              "2      28    male  33.000         3     no  southeast   4449.46200\n",
              "3      33    male  22.705         0     no  northwest  21984.47061\n",
              "4      32    male  28.880         0     no  northwest   3866.85520\n",
              "...   ...     ...     ...       ...    ...        ...          ...\n",
              "1333   50    male  30.970         3     no  northwest  10600.54830\n",
              "1334   18  female  31.920         0     no  northeast   2205.98080\n",
              "1335   18  female  36.850         0     no  southeast   1629.83350\n",
              "1336   21  female  25.800         0     no  southwest   2007.94500\n",
              "1337   61  female  29.070         0    yes  northwest  29141.36030\n",
              "\n",
              "[1338 rows x 7 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 20
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "AYpNzCYUlBEV"
      },
      "source": [
        "## Preprocessing the data"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Q-cG_aiJlO6D"
      },
      "source": [
        "from sklearn.compose import make_column_transformer\n",
        "from sklearn.preprocessing import MinMaxScaler, OneHotEncoder\n",
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "# Create a column transformer\n",
        "ct = make_column_transformer(\n",
        "    (MinMaxScaler(), [\"age\", \"bmi\", \"children\"]), #turn all values in these columns between 0 and 1\n",
        "    (OneHotEncoder(handle_unknown=\"ignore\"), [\"sex\", \"smoker\", \"region\"])\n",
        ")\n",
        "\n",
        "# Create X & y\n",
        "X = insurance.drop(\"charges\", axis=1)\n",
        "y = insurance[\"charges\"]\n",
        "\n",
        "#Build the train and test sets\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
        "\n",
        "# Fit the column transformer to the training data\n",
        "ct.fit(X_train)\n",
        "\n",
        "# Transform training and test data with normalization (MinMaxScaler) and OneHotEncoder\n",
        "X_train_normal = ct.transform(X_train)\n",
        "X_test_normal = ct.transform(X_test)"
      ],
      "execution_count": 21,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "eB-vSpoulXh9"
      },
      "source": [
        "The data has been normalized and one hot ecoded. Now the NN model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vZ_vwOAUlUct",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "f1ade012-7eb8-4c6c-c49b-364862e74fc9"
      },
      "source": [
        "# NN model to fit the normalized data\n",
        "tf.random.set_seed(42)\n",
        "\n",
        "# 1. Create the model\n",
        "insurance_model_4 = tf.keras.Sequential([\n",
        "                               tf.keras.layers.Dense(100),\n",
        "                               tf.keras.layers.Dense(50),\n",
        "                               tf.keras.layers.Dense(10),\n",
        "                               tf.keras.layers.Dense(1)\n",
        "])\n",
        "\n",
        "# 2. Compile the model\n",
        "insurance_model_4.compile(loss=tf.keras.losses.mae,\n",
        "                optimizer=tf.keras.optimizers.Adam(learning_rate=0.01),\n",
        "                metrics=[\"mae\"])\n",
        "\n",
        "# 3. Fit the model\n",
        "insurance_model_4.fit(X_train_normal, y_train, epochs=200)"
      ],
      "execution_count": 23,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/200\n",
            "34/34 [==============================] - 0s 2ms/step - loss: 12122.4551 - mae: 12122.4551\n",
            "Epoch 2/200\n",
            "34/34 [==============================] - 0s 2ms/step - loss: 7648.9434 - mae: 7648.9434\n",
            "Epoch 3/200\n",
            "34/34 [==============================] - 0s 2ms/step - loss: 5989.5879 - mae: 5989.5879\n",
            "Epoch 4/200\n",
            "34/34 [==============================] - 0s 1ms/step - loss: 3933.2312 - mae: 3933.2312\n",
            "Epoch 5/200\n",
            "34/34 [==============================] - 0s 2ms/step - loss: 3631.3118 - mae: 3631.3118\n",
            "Epoch 6/200\n",
            "34/34 [==============================] - 0s 2ms/step - loss: 3640.4832 - mae: 3640.4832\n",
            "Epoch 7/200\n",
            "34/34 [==============================] - 0s 2ms/step - loss: 3561.0747 - mae: 3561.0747\n",
            "Epoch 8/200\n",
            "34/34 [==============================] - 0s 2ms/step - loss: 3656.8723 - mae: 3656.8723\n",
            "Epoch 9/200\n",
            "34/34 [==============================] - 0s 2ms/step - loss: 3599.5771 - mae: 3599.5771\n",
            "Epoch 10/200\n",
            "34/34 [==============================] - 0s 2ms/step - loss: 3555.4492 - mae: 3555.4492\n",
            "Epoch 11/200\n",
            "34/34 [==============================] - 0s 2ms/step - loss: 3536.1841 - mae: 3536.1841\n",
            "Epoch 12/200\n",
            "34/34 [==============================] - 0s 1ms/step - loss: 3560.0681 - mae: 3560.0681\n",
            "Epoch 13/200\n",
            "34/34 [==============================] - 0s 1ms/step - loss: 3508.9863 - mae: 3508.9863\n",
            "Epoch 14/200\n",
            "34/34 [==============================] - 0s 1ms/step - loss: 3522.8704 - mae: 3522.8704\n",
            "Epoch 15/200\n",
            "34/34 [==============================] - 0s 2ms/step - loss: 3560.1787 - mae: 3560.1787\n",
            "Epoch 16/200\n",
            "34/34 [==============================] - 0s 1ms/step - loss: 3535.6128 - mae: 3535.6128\n",
            "Epoch 17/200\n",
            "34/34 [==============================] - 0s 1ms/step - loss: 3557.2908 - mae: 3557.2908\n",
            "Epoch 18/200\n",
            "34/34 [==============================] - 0s 2ms/step - loss: 3537.7595 - mae: 3537.7595\n",
            "Epoch 19/200\n",
            "34/34 [==============================] - 0s 2ms/step - loss: 3567.5859 - mae: 3567.5859\n",
            "Epoch 20/200\n",
            "34/34 [==============================] - 0s 2ms/step - loss: 3523.3635 - mae: 3523.3635\n",
            "Epoch 21/200\n",
            "34/34 [==============================] - 0s 1ms/step - loss: 3539.4080 - mae: 3539.4080\n",
            "Epoch 22/200\n",
            "34/34 [==============================] - 0s 2ms/step - loss: 3518.9668 - mae: 3518.9668\n",
            "Epoch 23/200\n",
            "34/34 [==============================] - 0s 2ms/step - loss: 3511.1702 - mae: 3511.1702\n",
            "Epoch 24/200\n",
            "34/34 [==============================] - 0s 2ms/step - loss: 3568.8545 - mae: 3568.8545\n",
            "Epoch 25/200\n",
            "34/34 [==============================] - 0s 2ms/step - loss: 3601.1094 - mae: 3601.1094\n",
            "Epoch 26/200\n",
            "34/34 [==============================] - 0s 2ms/step - loss: 3561.2317 - mae: 3561.2317\n",
            "Epoch 27/200\n",
            "34/34 [==============================] - 0s 2ms/step - loss: 3606.1050 - mae: 3606.1050\n",
            "Epoch 28/200\n",
            "34/34 [==============================] - 0s 2ms/step - loss: 3603.5979 - mae: 3603.5979\n",
            "Epoch 29/200\n",
            "34/34 [==============================] - 0s 2ms/step - loss: 3543.4460 - mae: 3543.4460\n",
            "Epoch 30/200\n",
            "34/34 [==============================] - 0s 2ms/step - loss: 3522.0012 - mae: 3522.0012\n",
            "Epoch 31/200\n",
            "34/34 [==============================] - 0s 1ms/step - loss: 3520.8315 - mae: 3520.8315\n",
            "Epoch 32/200\n",
            "34/34 [==============================] - 0s 2ms/step - loss: 3546.3616 - mae: 3546.3616\n",
            "Epoch 33/200\n",
            "34/34 [==============================] - 0s 2ms/step - loss: 3571.2463 - mae: 3571.2463\n",
            "Epoch 34/200\n",
            "34/34 [==============================] - 0s 2ms/step - loss: 3617.1057 - mae: 3617.1057\n",
            "Epoch 35/200\n",
            "34/34 [==============================] - 0s 2ms/step - loss: 3540.3201 - mae: 3540.3201\n",
            "Epoch 36/200\n",
            "34/34 [==============================] - 0s 1ms/step - loss: 3517.9309 - mae: 3517.9309\n",
            "Epoch 37/200\n",
            "34/34 [==============================] - 0s 2ms/step - loss: 3510.8079 - mae: 3510.8079\n",
            "Epoch 38/200\n",
            "34/34 [==============================] - 0s 2ms/step - loss: 3548.4507 - mae: 3548.4507\n",
            "Epoch 39/200\n",
            "34/34 [==============================] - 0s 2ms/step - loss: 3582.4097 - mae: 3582.4097\n",
            "Epoch 40/200\n",
            "34/34 [==============================] - 0s 2ms/step - loss: 3575.6716 - mae: 3575.6716\n",
            "Epoch 41/200\n",
            "34/34 [==============================] - 0s 2ms/step - loss: 3570.3555 - mae: 3570.3555\n",
            "Epoch 42/200\n",
            "34/34 [==============================] - 0s 2ms/step - loss: 3558.1143 - mae: 3558.1143\n",
            "Epoch 43/200\n",
            "34/34 [==============================] - 0s 2ms/step - loss: 3541.6182 - mae: 3541.6182\n",
            "Epoch 44/200\n",
            "34/34 [==============================] - 0s 2ms/step - loss: 3562.6548 - mae: 3562.6548\n",
            "Epoch 45/200\n",
            "34/34 [==============================] - 0s 2ms/step - loss: 3503.5007 - mae: 3503.5007\n",
            "Epoch 46/200\n",
            "34/34 [==============================] - 0s 2ms/step - loss: 3565.1416 - mae: 3565.1416\n",
            "Epoch 47/200\n",
            "34/34 [==============================] - 0s 1ms/step - loss: 3555.5479 - mae: 3555.5479\n",
            "Epoch 48/200\n",
            "34/34 [==============================] - 0s 2ms/step - loss: 3525.5830 - mae: 3525.5830\n",
            "Epoch 49/200\n",
            "34/34 [==============================] - 0s 2ms/step - loss: 3541.4895 - mae: 3541.4895\n",
            "Epoch 50/200\n",
            "34/34 [==============================] - 0s 2ms/step - loss: 3515.6311 - mae: 3515.6311\n",
            "Epoch 51/200\n",
            "34/34 [==============================] - 0s 2ms/step - loss: 3510.4182 - mae: 3510.4182\n",
            "Epoch 52/200\n",
            "34/34 [==============================] - 0s 2ms/step - loss: 3512.4702 - mae: 3512.4702\n",
            "Epoch 53/200\n",
            "34/34 [==============================] - 0s 2ms/step - loss: 3549.0894 - mae: 3549.0894\n",
            "Epoch 54/200\n",
            "34/34 [==============================] - 0s 2ms/step - loss: 3550.0996 - mae: 3550.0996\n",
            "Epoch 55/200\n",
            "34/34 [==============================] - 0s 2ms/step - loss: 3578.6218 - mae: 3578.6218\n",
            "Epoch 56/200\n",
            "34/34 [==============================] - 0s 1ms/step - loss: 3553.8433 - mae: 3553.8433\n",
            "Epoch 57/200\n",
            "34/34 [==============================] - 0s 2ms/step - loss: 3538.2749 - mae: 3538.2749\n",
            "Epoch 58/200\n",
            "34/34 [==============================] - 0s 2ms/step - loss: 3520.0642 - mae: 3520.0642\n",
            "Epoch 59/200\n",
            "34/34 [==============================] - 0s 2ms/step - loss: 3496.0237 - mae: 3496.0237\n",
            "Epoch 60/200\n",
            "34/34 [==============================] - 0s 2ms/step - loss: 3559.2166 - mae: 3559.2166\n",
            "Epoch 61/200\n",
            "34/34 [==============================] - 0s 2ms/step - loss: 3534.3701 - mae: 3534.3701\n",
            "Epoch 62/200\n",
            "34/34 [==============================] - 0s 2ms/step - loss: 3545.0842 - mae: 3545.0842\n",
            "Epoch 63/200\n",
            "34/34 [==============================] - 0s 2ms/step - loss: 3558.4082 - mae: 3558.4082\n",
            "Epoch 64/200\n",
            "34/34 [==============================] - 0s 2ms/step - loss: 3511.9680 - mae: 3511.9680\n",
            "Epoch 65/200\n",
            "34/34 [==============================] - 0s 2ms/step - loss: 3519.8625 - mae: 3519.8625\n",
            "Epoch 66/200\n",
            "34/34 [==============================] - 0s 2ms/step - loss: 3534.0876 - mae: 3534.0876\n",
            "Epoch 67/200\n",
            "34/34 [==============================] - 0s 2ms/step - loss: 3537.1912 - mae: 3537.1912\n",
            "Epoch 68/200\n",
            "34/34 [==============================] - 0s 2ms/step - loss: 3531.5815 - mae: 3531.5815\n",
            "Epoch 69/200\n",
            "34/34 [==============================] - 0s 2ms/step - loss: 3521.0420 - mae: 3521.0420\n",
            "Epoch 70/200\n",
            "34/34 [==============================] - 0s 2ms/step - loss: 3528.0823 - mae: 3528.0823\n",
            "Epoch 71/200\n",
            "34/34 [==============================] - 0s 2ms/step - loss: 3511.7073 - mae: 3511.7073\n",
            "Epoch 72/200\n",
            "34/34 [==============================] - 0s 2ms/step - loss: 3531.6826 - mae: 3531.6826\n",
            "Epoch 73/200\n",
            "34/34 [==============================] - 0s 2ms/step - loss: 3590.5039 - mae: 3590.5039\n",
            "Epoch 74/200\n",
            "34/34 [==============================] - 0s 2ms/step - loss: 3576.0317 - mae: 3576.0317\n",
            "Epoch 75/200\n",
            "34/34 [==============================] - 0s 2ms/step - loss: 3525.9663 - mae: 3525.9663\n",
            "Epoch 76/200\n",
            "34/34 [==============================] - 0s 2ms/step - loss: 3536.6084 - mae: 3536.6084\n",
            "Epoch 77/200\n",
            "34/34 [==============================] - 0s 2ms/step - loss: 3519.3997 - mae: 3519.3997\n",
            "Epoch 78/200\n",
            "34/34 [==============================] - 0s 2ms/step - loss: 3512.1726 - mae: 3512.1726\n",
            "Epoch 79/200\n",
            "34/34 [==============================] - 0s 2ms/step - loss: 3566.9668 - mae: 3566.9668\n",
            "Epoch 80/200\n",
            "34/34 [==============================] - 0s 2ms/step - loss: 3611.8789 - mae: 3611.8789\n",
            "Epoch 81/200\n",
            "34/34 [==============================] - 0s 2ms/step - loss: 3624.7810 - mae: 3624.7810\n",
            "Epoch 82/200\n",
            "34/34 [==============================] - 0s 1ms/step - loss: 3574.8713 - mae: 3574.8713\n",
            "Epoch 83/200\n",
            "34/34 [==============================] - 0s 1ms/step - loss: 3536.5925 - mae: 3536.5925\n",
            "Epoch 84/200\n",
            "34/34 [==============================] - 0s 2ms/step - loss: 3590.0557 - mae: 3590.0557\n",
            "Epoch 85/200\n",
            "34/34 [==============================] - 0s 2ms/step - loss: 3525.0789 - mae: 3525.0789\n",
            "Epoch 86/200\n",
            "34/34 [==============================] - 0s 1ms/step - loss: 3538.3726 - mae: 3538.3726\n",
            "Epoch 87/200\n",
            "34/34 [==============================] - 0s 2ms/step - loss: 3549.1309 - mae: 3549.1309\n",
            "Epoch 88/200\n",
            "34/34 [==============================] - 0s 2ms/step - loss: 3532.6836 - mae: 3532.6836\n",
            "Epoch 89/200\n",
            "34/34 [==============================] - 0s 2ms/step - loss: 3508.4041 - mae: 3508.4041\n",
            "Epoch 90/200\n",
            "34/34 [==============================] - 0s 2ms/step - loss: 3527.9458 - mae: 3527.9458\n",
            "Epoch 91/200\n",
            "34/34 [==============================] - 0s 2ms/step - loss: 3535.5444 - mae: 3535.5444\n",
            "Epoch 92/200\n",
            "34/34 [==============================] - 0s 2ms/step - loss: 3614.1458 - mae: 3614.1458\n",
            "Epoch 93/200\n",
            "34/34 [==============================] - 0s 2ms/step - loss: 3604.3779 - mae: 3604.3779\n",
            "Epoch 94/200\n",
            "34/34 [==============================] - 0s 2ms/step - loss: 3531.4375 - mae: 3531.4375\n",
            "Epoch 95/200\n",
            "34/34 [==============================] - 0s 2ms/step - loss: 3525.7170 - mae: 3525.7170\n",
            "Epoch 96/200\n",
            "34/34 [==============================] - 0s 2ms/step - loss: 3521.7444 - mae: 3521.7444\n",
            "Epoch 97/200\n",
            "34/34 [==============================] - 0s 2ms/step - loss: 3584.1057 - mae: 3584.1057\n",
            "Epoch 98/200\n",
            "34/34 [==============================] - 0s 2ms/step - loss: 3527.9507 - mae: 3527.9507\n",
            "Epoch 99/200\n",
            "34/34 [==============================] - 0s 2ms/step - loss: 3548.6633 - mae: 3548.6633\n",
            "Epoch 100/200\n",
            "34/34 [==============================] - 0s 2ms/step - loss: 3508.9241 - mae: 3508.9241\n",
            "Epoch 101/200\n",
            "34/34 [==============================] - 0s 2ms/step - loss: 3513.6787 - mae: 3513.6787\n",
            "Epoch 102/200\n",
            "34/34 [==============================] - 0s 1ms/step - loss: 3604.8267 - mae: 3604.8267\n",
            "Epoch 103/200\n",
            "34/34 [==============================] - 0s 2ms/step - loss: 3538.2485 - mae: 3538.2485\n",
            "Epoch 104/200\n",
            "34/34 [==============================] - 0s 1ms/step - loss: 3518.0930 - mae: 3518.0930\n",
            "Epoch 105/200\n",
            "34/34 [==============================] - 0s 2ms/step - loss: 3554.6084 - mae: 3554.6084\n",
            "Epoch 106/200\n",
            "34/34 [==============================] - 0s 2ms/step - loss: 3524.9041 - mae: 3524.9041\n",
            "Epoch 107/200\n",
            "34/34 [==============================] - 0s 2ms/step - loss: 3531.1042 - mae: 3531.1042\n",
            "Epoch 108/200\n",
            "34/34 [==============================] - 0s 2ms/step - loss: 3514.1023 - mae: 3514.1023\n",
            "Epoch 109/200\n",
            "34/34 [==============================] - 0s 2ms/step - loss: 3548.1133 - mae: 3548.1133\n",
            "Epoch 110/200\n",
            "34/34 [==============================] - 0s 2ms/step - loss: 3516.8315 - mae: 3516.8315\n",
            "Epoch 111/200\n",
            "34/34 [==============================] - 0s 2ms/step - loss: 3545.1851 - mae: 3545.1851\n",
            "Epoch 112/200\n",
            "34/34 [==============================] - 0s 2ms/step - loss: 3549.9192 - mae: 3549.9192\n",
            "Epoch 113/200\n",
            "34/34 [==============================] - 0s 2ms/step - loss: 3632.3586 - mae: 3632.3586\n",
            "Epoch 114/200\n",
            "34/34 [==============================] - 0s 2ms/step - loss: 3541.0098 - mae: 3541.0098\n",
            "Epoch 115/200\n",
            "34/34 [==============================] - 0s 2ms/step - loss: 3528.0144 - mae: 3528.0144\n",
            "Epoch 116/200\n",
            "34/34 [==============================] - 0s 2ms/step - loss: 3577.4253 - mae: 3577.4253\n",
            "Epoch 117/200\n",
            "34/34 [==============================] - 0s 2ms/step - loss: 3509.5908 - mae: 3509.5908\n",
            "Epoch 118/200\n",
            "34/34 [==============================] - 0s 1ms/step - loss: 3503.5942 - mae: 3503.5942\n",
            "Epoch 119/200\n",
            "34/34 [==============================] - 0s 2ms/step - loss: 3491.9075 - mae: 3491.9075\n",
            "Epoch 120/200\n",
            "34/34 [==============================] - 0s 1ms/step - loss: 3491.0835 - mae: 3491.0835\n",
            "Epoch 121/200\n",
            "34/34 [==============================] - 0s 2ms/step - loss: 3525.4731 - mae: 3525.4731\n",
            "Epoch 122/200\n",
            "34/34 [==============================] - 0s 2ms/step - loss: 3540.7302 - mae: 3540.7302\n",
            "Epoch 123/200\n",
            "34/34 [==============================] - 0s 2ms/step - loss: 3547.9287 - mae: 3547.9287\n",
            "Epoch 124/200\n",
            "34/34 [==============================] - 0s 2ms/step - loss: 3522.9272 - mae: 3522.9272\n",
            "Epoch 125/200\n",
            "34/34 [==============================] - 0s 2ms/step - loss: 3524.9792 - mae: 3524.9792\n",
            "Epoch 126/200\n",
            "34/34 [==============================] - 0s 2ms/step - loss: 3560.6960 - mae: 3560.6960\n",
            "Epoch 127/200\n",
            "34/34 [==============================] - 0s 2ms/step - loss: 3514.8257 - mae: 3514.8257\n",
            "Epoch 128/200\n",
            "34/34 [==============================] - 0s 2ms/step - loss: 3565.2637 - mae: 3565.2637\n",
            "Epoch 129/200\n",
            "34/34 [==============================] - 0s 1ms/step - loss: 3559.9126 - mae: 3559.9126\n",
            "Epoch 130/200\n",
            "34/34 [==============================] - 0s 2ms/step - loss: 3576.8667 - mae: 3576.8667\n",
            "Epoch 131/200\n",
            "34/34 [==============================] - 0s 2ms/step - loss: 3488.7732 - mae: 3488.7732\n",
            "Epoch 132/200\n",
            "34/34 [==============================] - 0s 2ms/step - loss: 3559.7947 - mae: 3559.7947\n",
            "Epoch 133/200\n",
            "34/34 [==============================] - 0s 2ms/step - loss: 3528.8545 - mae: 3528.8545\n",
            "Epoch 134/200\n",
            "34/34 [==============================] - 0s 2ms/step - loss: 3523.5872 - mae: 3523.5872\n",
            "Epoch 135/200\n",
            "34/34 [==============================] - 0s 2ms/step - loss: 3527.6099 - mae: 3527.6099\n",
            "Epoch 136/200\n",
            "34/34 [==============================] - 0s 2ms/step - loss: 3508.1470 - mae: 3508.1470\n",
            "Epoch 137/200\n",
            "34/34 [==============================] - 0s 2ms/step - loss: 3508.0112 - mae: 3508.0112\n",
            "Epoch 138/200\n",
            "34/34 [==============================] - 0s 2ms/step - loss: 3539.8276 - mae: 3539.8276\n",
            "Epoch 139/200\n",
            "34/34 [==============================] - 0s 2ms/step - loss: 3538.1914 - mae: 3538.1914\n",
            "Epoch 140/200\n",
            "34/34 [==============================] - 0s 2ms/step - loss: 3536.2678 - mae: 3536.2678\n",
            "Epoch 141/200\n",
            "34/34 [==============================] - 0s 2ms/step - loss: 3565.0916 - mae: 3565.0916\n",
            "Epoch 142/200\n",
            "34/34 [==============================] - 0s 1ms/step - loss: 3570.1445 - mae: 3570.1445\n",
            "Epoch 143/200\n",
            "34/34 [==============================] - 0s 2ms/step - loss: 3524.4763 - mae: 3524.4763\n",
            "Epoch 144/200\n",
            "34/34 [==============================] - 0s 2ms/step - loss: 3516.8853 - mae: 3516.8853\n",
            "Epoch 145/200\n",
            "34/34 [==============================] - 0s 2ms/step - loss: 3517.1396 - mae: 3517.1396\n",
            "Epoch 146/200\n",
            "34/34 [==============================] - 0s 2ms/step - loss: 3545.9407 - mae: 3545.9404\n",
            "Epoch 147/200\n",
            "34/34 [==============================] - 0s 2ms/step - loss: 3549.5066 - mae: 3549.5066\n",
            "Epoch 148/200\n",
            "34/34 [==============================] - 0s 2ms/step - loss: 3544.1746 - mae: 3544.1746\n",
            "Epoch 149/200\n",
            "34/34 [==============================] - 0s 2ms/step - loss: 3500.9834 - mae: 3500.9834\n",
            "Epoch 150/200\n",
            "34/34 [==============================] - 0s 2ms/step - loss: 3505.9246 - mae: 3505.9246\n",
            "Epoch 151/200\n",
            "34/34 [==============================] - 0s 2ms/step - loss: 3538.8398 - mae: 3538.8398\n",
            "Epoch 152/200\n",
            "34/34 [==============================] - 0s 2ms/step - loss: 3637.8301 - mae: 3637.8301\n",
            "Epoch 153/200\n",
            "34/34 [==============================] - 0s 2ms/step - loss: 3517.3308 - mae: 3517.3308\n",
            "Epoch 154/200\n",
            "34/34 [==============================] - 0s 2ms/step - loss: 3538.5051 - mae: 3538.5051\n",
            "Epoch 155/200\n",
            "34/34 [==============================] - 0s 2ms/step - loss: 3539.2571 - mae: 3539.2571\n",
            "Epoch 156/200\n",
            "34/34 [==============================] - 0s 2ms/step - loss: 3540.1934 - mae: 3540.1934\n",
            "Epoch 157/200\n",
            "34/34 [==============================] - 0s 2ms/step - loss: 3518.4592 - mae: 3518.4592\n",
            "Epoch 158/200\n",
            "34/34 [==============================] - 0s 2ms/step - loss: 3520.6707 - mae: 3520.6707\n",
            "Epoch 159/200\n",
            "34/34 [==============================] - 0s 2ms/step - loss: 3498.5364 - mae: 3498.5364\n",
            "Epoch 160/200\n",
            "34/34 [==============================] - 0s 3ms/step - loss: 3603.5793 - mae: 3603.5793\n",
            "Epoch 161/200\n",
            "34/34 [==============================] - 0s 2ms/step - loss: 3523.4932 - mae: 3523.4932\n",
            "Epoch 162/200\n",
            "34/34 [==============================] - 0s 2ms/step - loss: 3507.9243 - mae: 3507.9243\n",
            "Epoch 163/200\n",
            "34/34 [==============================] - 0s 2ms/step - loss: 3526.8669 - mae: 3526.8669\n",
            "Epoch 164/200\n",
            "34/34 [==============================] - 0s 2ms/step - loss: 3599.5464 - mae: 3599.5464\n",
            "Epoch 165/200\n",
            "34/34 [==============================] - 0s 2ms/step - loss: 3525.0129 - mae: 3525.0129\n",
            "Epoch 166/200\n",
            "34/34 [==============================] - 0s 2ms/step - loss: 3507.4509 - mae: 3507.4509\n",
            "Epoch 167/200\n",
            "34/34 [==============================] - 0s 2ms/step - loss: 3515.7161 - mae: 3515.7161\n",
            "Epoch 168/200\n",
            "34/34 [==============================] - 0s 1ms/step - loss: 3523.0728 - mae: 3523.0728\n",
            "Epoch 169/200\n",
            "34/34 [==============================] - 0s 2ms/step - loss: 3526.8965 - mae: 3526.8965\n",
            "Epoch 170/200\n",
            "34/34 [==============================] - 0s 2ms/step - loss: 3517.0476 - mae: 3517.0476\n",
            "Epoch 171/200\n",
            "34/34 [==============================] - 0s 2ms/step - loss: 3520.8062 - mae: 3520.8062\n",
            "Epoch 172/200\n",
            "34/34 [==============================] - 0s 2ms/step - loss: 3563.3008 - mae: 3563.3008\n",
            "Epoch 173/200\n",
            "34/34 [==============================] - 0s 2ms/step - loss: 3521.1665 - mae: 3521.1665\n",
            "Epoch 174/200\n",
            "34/34 [==============================] - 0s 2ms/step - loss: 3499.3540 - mae: 3499.3540\n",
            "Epoch 175/200\n",
            "34/34 [==============================] - 0s 2ms/step - loss: 3554.3296 - mae: 3554.3296\n",
            "Epoch 176/200\n",
            "34/34 [==============================] - 0s 2ms/step - loss: 3534.8479 - mae: 3534.8479\n",
            "Epoch 177/200\n",
            "34/34 [==============================] - 0s 2ms/step - loss: 3526.6748 - mae: 3526.6748\n",
            "Epoch 178/200\n",
            "34/34 [==============================] - 0s 2ms/step - loss: 3525.1045 - mae: 3525.1045\n",
            "Epoch 179/200\n",
            "34/34 [==============================] - 0s 2ms/step - loss: 3613.1123 - mae: 3613.1123\n",
            "Epoch 180/200\n",
            "34/34 [==============================] - 0s 2ms/step - loss: 3540.2002 - mae: 3540.2002\n",
            "Epoch 181/200\n",
            "34/34 [==============================] - 0s 2ms/step - loss: 3546.7004 - mae: 3546.7004\n",
            "Epoch 182/200\n",
            "34/34 [==============================] - 0s 2ms/step - loss: 3524.9160 - mae: 3524.9160\n",
            "Epoch 183/200\n",
            "34/34 [==============================] - 0s 2ms/step - loss: 3515.3467 - mae: 3515.3467\n",
            "Epoch 184/200\n",
            "34/34 [==============================] - 0s 2ms/step - loss: 3549.0664 - mae: 3549.0664\n",
            "Epoch 185/200\n",
            "34/34 [==============================] - 0s 2ms/step - loss: 3535.4170 - mae: 3535.4170\n",
            "Epoch 186/200\n",
            "34/34 [==============================] - 0s 2ms/step - loss: 3609.5723 - mae: 3609.5723\n",
            "Epoch 187/200\n",
            "34/34 [==============================] - 0s 2ms/step - loss: 3536.5720 - mae: 3536.5720\n",
            "Epoch 188/200\n",
            "34/34 [==============================] - 0s 2ms/step - loss: 3520.4702 - mae: 3520.4702\n",
            "Epoch 189/200\n",
            "34/34 [==============================] - 0s 2ms/step - loss: 3545.7400 - mae: 3545.7400\n",
            "Epoch 190/200\n",
            "34/34 [==============================] - 0s 3ms/step - loss: 3537.0251 - mae: 3537.0251\n",
            "Epoch 191/200\n",
            "34/34 [==============================] - 0s 2ms/step - loss: 3552.7617 - mae: 3552.7617\n",
            "Epoch 192/200\n",
            "34/34 [==============================] - 0s 2ms/step - loss: 3559.0896 - mae: 3559.0896\n",
            "Epoch 193/200\n",
            "34/34 [==============================] - 0s 2ms/step - loss: 3558.2307 - mae: 3558.2307\n",
            "Epoch 194/200\n",
            "34/34 [==============================] - 0s 2ms/step - loss: 3509.5505 - mae: 3509.5505\n",
            "Epoch 195/200\n",
            "34/34 [==============================] - 0s 2ms/step - loss: 3529.9670 - mae: 3529.9670\n",
            "Epoch 196/200\n",
            "34/34 [==============================] - 0s 2ms/step - loss: 3528.2437 - mae: 3528.2437\n",
            "Epoch 197/200\n",
            "34/34 [==============================] - 0s 2ms/step - loss: 3608.3560 - mae: 3608.3560\n",
            "Epoch 198/200\n",
            "34/34 [==============================] - 0s 2ms/step - loss: 3522.3396 - mae: 3522.3396\n",
            "Epoch 199/200\n",
            "34/34 [==============================] - 0s 2ms/step - loss: 3536.7922 - mae: 3536.7922\n",
            "Epoch 200/200\n",
            "34/34 [==============================] - 0s 2ms/step - loss: 3502.2996 - mae: 3502.2996\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tensorflow.python.keras.callbacks.History at 0x7f1df0a834d0>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 23
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qvPWQENPrLrH"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}